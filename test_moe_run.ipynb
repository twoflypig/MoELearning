{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "f7dd7a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Parameter\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1cdee0",
   "metadata": {},
   "source": [
    "# MoE的主要步骤\n",
    "\n",
    "MoE主要是将输入的token表示根据特定的路由方式，路由到不同的专家上去，以期望每个token能够选择到适合自己的专家。因此其核心的过程主要分为如下几步：\n",
    "\n",
    "## 求解token应该找哪个专家\n",
    "那么第一步，先把输入按数据并行的方式输入。例如\\[bs, seq, d_model\\]的输入logits，可以得到\\[n_cores, to]\n",
    "\n",
    "## 按照选择的专家，将输入表征从以卡的维度转换到专家维度(AllToAll)产生的来源。\n",
    "\n",
    "- dispatch tensor。依赖dispatch tensor将token进行划分\n",
    "- combine tensor输出概率\n",
    "\n",
    "\n",
    "##  将每个专家的输出乘以概率，得到最终输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13d196a-8f45-40ed-84f1-6fcbc3f33807",
   "metadata": {},
   "source": [
    "# 定义\n",
    "在计算开始前，我们先阐释下变量的定义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "2bc922b3-4a7e-4963-9ae8-fde28d3e4dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cores = 2 # 卡数\n",
    "tokens_per_core = 4 # 每张卡有多少bs\n",
    "expert_num = 2 # 专家的数量\n",
    "d_model=1 # 向量的隐藏层维度\n",
    "expert_capacity =3 # 每个专家能够处理的token数目，表示专家的Bs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06f05a5",
   "metadata": {},
   "source": [
    "## 输入\n",
    "一般来讲，MoE的输入维度为[bs, seq_length, d_model]。在此我们先随机初始化一个输入。为了方便观察在MoE中的路由机制，输入是怎么重新排布的，我们将输入截取到小数点后两位。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "7f8173c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9200],\n",
      "         [0.2700],\n",
      "         [0.2100],\n",
      "         [0.6600]],\n",
      "\n",
      "        [[0.5800],\n",
      "         [0.6900],\n",
      "         [0.7200],\n",
      "         [0.5000]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor(\n",
    "np.around(np.random.random((n_cores, tokens_per_core, d_model)), 2))\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b4af45",
   "metadata": {},
   "source": [
    "# 路由机制\n",
    "\n",
    "## 求解每个token应该选择哪些专家\n",
    "\n",
    "首先根据输入，经过一个Linear层求得输入的每个token在每个专家上的概率。然后通过topk求得概率最高的几个专家。\n",
    "\n",
    "\n",
    "$$\n",
    "logits = inputs*weight \\\\ \n",
    "pro = softmax(logits) \\\\\n",
    "pro, index = topk(pro)  \\\\\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "a0464d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.softmax(torch.nn.Linear(d_model, expert_num)(inputs.type(torch.float32)), axis=-1)\n",
    "logits = logits.type(torch.float64)\n",
    "expert_gate, expert_index = logits.topk(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f4df5",
   "metadata": {},
   "source": [
    "## 将超过专家自己容量的token进行丢弃\n",
    "\n",
    "因为每个专家拥有自己的batch size，所以需要通过累计求和的方式，记录每个专家到第k个token为止，已经被多少个token选择的。需要通过mask的方式，将超过专家自己容量的token丢弃。\n",
    "\n",
    "具体的实现步骤如下：\n",
    "\n",
    "### 记录每个专家选择了哪几个token\n",
    "\n",
    "此处的expert_index的shape为[num_cores, tokens_per_token, 1]。表示每个token选择了第几个专家。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "1f24d62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_index = expert_index.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "24bf5247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([2, 4, 1]) torch.Size([2, 4]) tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "print(\"\", expert_gate.shape, expert_index.shape, expert_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "9b33f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_mask = F.one_hot(expert_index, expert_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "30f3f890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 2])\n",
      "tensor([[[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1]],\n",
      "\n",
      "        [[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1]]])\n"
     ]
    }
   ],
   "source": [
    "print(expert_mask.shape)\n",
    "print(expert_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75bb26a",
   "metadata": {},
   "source": [
    "### 按专家的维度，累计每个专家token选择的数量\n",
    "\n",
    "既然已经通过one_hot后的expert_mask知道了每个token选择了第几个专家，那么只需要按tokens_per_core的维度，对one_hot的索引进行累计求和，即可获得每个专家被索引的数量。\n",
    "\n",
    "在此处引入了position_in_expert。position_in_expert描述了每个token选择的。表示每张卡，到第k个token为止，每个专家已经被选择的个数。那为什么乘以自己的mask呢？以token的角度，只需要看到自己选择的专家已经有的token数就好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "20df78d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_in_expert = torch.cumsum(expert_mask, 1)*expert_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "8a1699d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1],\n",
       "         [0, 2],\n",
       "         [0, 3],\n",
       "         [0, 4]],\n",
       "\n",
       "        [[0, 1],\n",
       "         [0, 2],\n",
       "         [0, 3],\n",
       "         [0, 4]]])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_in_expert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee05f11",
   "metadata": {},
   "source": [
    "我们为每个专家选择的tokens数目不能超过一定的上限，因此需要将他们进行限制。具体的做法就是先求每个专家已经拥有的token数目，如果从第k个token开始，某个专家的token数目已经超过了expert_capacity,那么对应的token当前选择的专家就会被置为0。\n",
    "\n",
    "**从这里推断，目前论文中给的伪代码实现有些问题，就是如果当前设置的容量过小，那么顺序先的的token就会排到某个专家。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "d70e0d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_mask = expert_mask * torch.less(position_in_expert, expert_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "25008bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 0],\n",
      "         [0, 0]],\n",
      "\n",
      "        [[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 0],\n",
      "         [0, 0]]])\n",
      "torch.Size([2, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "print(expert_mask)\n",
    "print(expert_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bf3866",
   "metadata": {},
   "source": [
    "expert_mask是独热编码表示，因此超过上限时，对应的值为0，就可以起到越界清零的作用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "32dad285",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_mask_flat = torch.sum(expert_mask, -1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "5c2b5ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0]]])"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_mask_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8d6ed0",
   "metadata": {},
   "source": [
    "## 计算combine tensor\n",
    "combine tensor是用来结合专家的输出和对应的路由概率的，对应的shape为\n",
    "\\[num_cores, tokens_per_core, num_experts, expert_capacity\\]。\n",
    "因为我们已经获得了每个token选择的专家概率以及对应的专家(top1)，所以需要将得到对应的专家的概率，并且将没选择到的专家置为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "98c1f728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert gate shape torch.Size([2, 4, 1])\n",
      "Expert mask flatter shape torch.Size([2, 4, 1])\n",
      "expert_index shape: torch.Size([2, 4])\n",
      "Position in expert shape: torch.Size([2, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "print(\"Expert gate shape\", expert_gate.shape)\n",
    "print(\"Expert mask flatter shape\", expert_mask_flat.shape)\n",
    "print(\"expert_index shape:\", expert_index.shape)\n",
    "print(\"Position in expert shape:\", position_in_expert.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9b26ab",
   "metadata": {},
   "source": [
    "expert_index表示每个token选择了第几个专家。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "1b46cc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a61b6-c7d0-4859-8dc9-f3049c88015f",
   "metadata": {},
   "source": [
    "先计算每个专家mask掉的词。对应的计算方法是输出*被mask掉的词\n",
    "\n",
    "expert_gate * expert_mask_flat表示每个专家的概率*有效的token。即超过每个专家bs的token概率会被清零。\n",
    "\n",
    "紧接着再* F.one_hot(expert_index, expert_num))， 表示将概率乘以独热编码的形式\n",
    "\n",
    "表示token中选中的expert，以及对应的概率。其他不相关的experter专家数目会变成0。这样就形成了top1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "8dcaa11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.8233],\n",
      "         [0.0000, 0.7984],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.8272],\n",
      "         [0.0000, 0.8373],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]], dtype=torch.float64, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "expert_outputs = \\\n",
    "(expert_gate * expert_mask_flat * F.one_hot(expert_index, expert_num))\n",
    "expert_outputs.shape\n",
    "print(expert_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bb2872-933f-4fdb-8b4d-65bf017a3a36",
   "metadata": {},
   "source": [
    "## CombinedTensor的含义\n",
    "\n",
    "shape [num_cores, tokens_per_core, num_experts, expert_capacity]\n",
    "\n",
    "表示的是从token视角到专家视角后，每个token选择的专家概率。\n",
    "\n",
    "为什么还要把专家的输出乘以postion_in_experts?expert_mask是为了掩码掉超过每个专家的bs的输出的。因此将超过的置为0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "0181736a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 1], [0, 1], [0, 0], [0, 0]], [[0, 1], [0, 1], [0, 0], [0, 0]]]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_mask.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "4e96d0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 1], [0, 2], [0, 3], [0, 4]], [[0, 1], [0, 2], [0, 3], [0, 4]]]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_in_expert.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "5b194172",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_position_in_expert = position_in_expert*expert_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "26b31f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 2, 3])\n",
      "[[[[0.0, 0.0, 0.0], [0.0, 0.8232826590538025, 0.0]],\n",
      "  [[0.0, 0.0, 0.0], [0.0, 0.0, 0.7984247207641602]],\n",
      "  [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]],\n",
      "  [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]],\n",
      " [[[0.0, 0.0, 0.0], [0.0, 0.8271830677986145, 0.0]],\n",
      "  [[0.0, 0.0, 0.0], [0.0, 0.0, 0.837250828742981]],\n",
      "  [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]],\n",
      "  [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]]]\n"
     ]
    }
   ],
   "source": [
    "combined_tensor = expert_outputs.unsqueeze(-1)* \\\n",
    "F.one_hot(masked_position_in_expert, expert_capacity)\n",
    "print(combined_tensor.shape)\n",
    "# 表示 [num_cores, tokens_per_core, num_experts, expert_capacity]\n",
    "pprint(combined_tensor.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "84e1edd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.0, 0.0, 0.0], [0.0, 0.8232826590538025, 0.0]],\n",
      "  [[0.0, 0.0, 0.0], [0.0, 0.0, 0.7984247207641602]],\n",
      "  [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]],\n",
      "  [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]],\n",
      " [[[0.0, 0.0, 0.0], [0.0, 0.8271830677986145, 0.0]],\n",
      "  [[0.0, 0.0, 0.0], [0.0, 0.0, 0.837250828742981]],\n",
      "  [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]],\n",
      "  [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]]]\n"
     ]
    }
   ],
   "source": [
    "#print(combined_tensor.shape)\n",
    "pprint(combined_tensor.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd630d5a-05c4-4a02-bfab-415408618def",
   "metadata": {},
   "source": [
    "## dispatch tensor\n",
    "dispatch_tensor的是从conbined_tensor中转换而来的，存在值的cast为True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "8edfe47d-5638-49e7-a021-aecd6640cec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[False, False, False], [False, True, False]],\n",
      "  [[False, False, False], [False, False, True]],\n",
      "  [[False, False, False], [False, False, False]],\n",
      "  [[False, False, False], [False, False, False]]],\n",
      " [[[False, False, False], [False, True, False]],\n",
      "  [[False, False, False], [False, False, True]],\n",
      "  [[False, False, False], [False, False, False]],\n",
      "  [[False, False, False], [False, False, False]]]]\n"
     ]
    }
   ],
   "source": [
    "dispatch_tensor = combined_tensor.type(torch.bool)\n",
    "pprint(dispatch_tensor.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cef8e05-3258-460f-b576-9cb28a892f70",
   "metadata": {},
   "source": [
    "# SwitchLayer\n",
    "论文中描述，是通过一个大的batchmul乘法将输出assign给对应的专家的。即根据上面routing获得的mask表示，将输入以专家的维度去进行重新排位置。那怎么进行重新排位置呢？这里的实现使用一个BatchMatmul矩阵实现的。\n",
    "\n",
    "为什么需要这样一个转换？因为在进入MoE层之前，tensor的视角是每卡有多少token的，即[num_cores, tokens_per_core]。而MoE层的处理视角是按专家维度的，对应的视角为[num_experts, tokens_per_experts(expert_capacity)]。所以需要一个从两种映射维度之间的转换。这个转换就是Mask矩阵。\n",
    "\n",
    "dispatch_tensor\n",
    "\n",
    ">[num_cores, tokens_per_core, num_experts, expert_capacity]\n",
    ">[i, j, k, n]\n",
    "\n",
    "和输入inputs \n",
    "\n",
    ">[num_cores, tokens_per_core, d_model]\n",
    ">[i, j, a]\n",
    "\n",
    "输出为 : \n",
    "\n",
    ">[num_experts, num_cores, expert_capacity, d_model]\n",
    ">[k, i, n, a]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5144c31",
   "metadata": {},
   "source": [
    "## 一个小例子\n",
    "如果我由一个[0.1, 0.2, 0.3]的一个小矩阵，那么怎么把它重新弄成[0.3, 0.2, 0.1]的一个矩阵呢？有下述的几种做法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf20229",
   "metadata": {},
   "source": [
    "### 利用MatMul的累加性质进行重新排布\n",
    "\n",
    "即 [1, 3] x [3, 3] -> [1, 3]。利用矩阵的累加机制，进行logits的重新排位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "35fe17cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[0.1, 0.2, 0.3]]).type(torch.float32)\n",
    "mask = torch.tensor([\n",
    "    [0, 0, 1],\n",
    "    [0, 1, 0],\n",
    "    [1, 0, 0],\n",
    "]).type(torch.float32)\n",
    "print(x.shape)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "22890631",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.einsum('ij,jk->ik', x, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "671099b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3000, 0.2000, 0.1000]])\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "4f6ac534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "### 利用gather操作\n",
    "x = torch.tensor([[0.1, 0.2, 0.3]]).type(torch.float32)\n",
    "mask = torch.tensor([[2, 1, 0]]).type(torch.int64)\n",
    "print(x.shape)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "e74e23d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.gather(x, 1, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "4c0d7e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3000, 0.2000, 0.1000]])\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f0b457",
   "metadata": {},
   "source": [
    "## 论文中实现版本：回到输入的重排布\n",
    "\n",
    "通过修改dispatch_tensor的值，怎么发现里面会对同一个专家的相同位置进行求和的？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ed8adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "1729d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_tensor = combined_tensor.type(torch.bool).type(torch.float64)\n",
    "# dispatch_tensor[0,1, 0, 1]=0\n",
    "# dispatch_tensor[0,2, 1, 2]=1\n",
    "expert_inputs = torch.einsum('ijkn,ija->kina', dispatch_tensor, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "367359fe",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 1])\n",
      "[[[0.45], [0.27], [0.82], [0.23]], [[0.48], [0.56], [0.54], [0.75]]]\n"
     ]
    }
   ],
   "source": [
    "# 输入的inputs\n",
    "pprint(inputs.shape)\n",
    "pprint(inputs.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "133c0b88-afe0-42e8-befd-604de519bda6",
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[[0.0, 0.0, 0.0], [0.0, 1.0, 0.0]],\n",
       "  [[0.0, 0.0, 0.0], [0.0, 0.0, 1.0]],\n",
       "  [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]],\n",
       "  [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]],\n",
       " [[[0.0, 0.0, 0.0], [0.0, 1.0, 0.0]],\n",
       "  [[0.0, 0.0, 0.0], [0.0, 0.0, 1.0]],\n",
       "  [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]],\n",
       "  [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]]]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输出的mask矩阵\n",
    "pprint(dispatch_tensor.shape)\n",
    "dispatch_tensor.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "fc5bf141",
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3, 1])\n",
      "[[[[0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0]]],\n",
      " [[[0.0], [0.45], [0.27]], [[0.0], [0.48], [0.56]]]]\n",
      "tensor([[[[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000],\n",
      "          [0.4500],\n",
      "          [0.2700]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.4800],\n",
      "          [0.5600]]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "pprint(expert_inputs.shape)\n",
    "pprint(expert_inputs.tolist())\n",
    "print(expert_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "1e065e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1000, dtype=torch.float64)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b42bd53",
   "metadata": {},
   "source": [
    "### 利用gather实现输入重排布\n",
    "\n",
    "主要思路就是，利用position_in_expert，将inputs [num_cores, tokens_per_core, d_model]转换为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "36f7258d-427f-477a-9e62-80732dfd4009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1])\n",
      "[[1], [1], [1], [1]]\n"
     ]
    }
   ],
   "source": [
    "# 专家数 [num_cores, tokens_per_core, num_experts]\n",
    "print(masked_position_in_expert.shape)\n",
    "pprint(masked_position_in_expert.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "debba966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 1])\n",
      "[[[0.36], [0.96], [0.42], [0.36]]]\n"
     ]
    }
   ],
   "source": [
    "# 输入的inputs\n",
    "# [num_cores, tokens_per_core, d_model]\n",
    "pprint(inputs.shape)\n",
    "pprint(inputs.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "e04c19b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "?torch.Tensor.scatter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f2a5b80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_empty = torch.zeros((2, 2, 3, 2)).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "7b525485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 1])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_position_in_expert.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "81cab4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 1],\n",
       "          [0, 0]],\n",
       "\n",
       "         [[0, 0],\n",
       "          [1, 1]],\n",
       "\n",
       "         [[0, 0],\n",
       "          [2, 2]],\n",
       "\n",
       "         [[0, 0],\n",
       "          [0, 0]]],\n",
       "\n",
       "\n",
       "        [[[0, 0],\n",
       "          [1, 1]],\n",
       "\n",
       "         [[0, 0],\n",
       "          [2, 2]],\n",
       "\n",
       "         [[1, 1],\n",
       "          [0, 0]],\n",
       "\n",
       "         [[2, 2],\n",
       "          [0, 0]]]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_position_in_expert.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3e0c839a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Index tensor must have the same number of dimensions as self tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_101656/3833232305.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_position_in_expert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Index tensor must have the same number of dimensions as self tensor"
     ]
    }
   ],
   "source": [
    "torch.scatter(inputs, 2, masked_position_in_expert.unsqueeze(-1).expand(2, 4, 2, 2), out_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "92538868-ea83-4488-8d87-a2bc1f0a220d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "out = torch.gather(inputs, 1, masked_position_in_expert)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e447f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "250px",
    "width": "328px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "368px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
